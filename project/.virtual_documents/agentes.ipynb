get_ipython().run_line_magic("load_ext", " autoreload")
get_ipython().run_line_magic("autoreload", " 2")


import nest_asyncio

nest_asyncio.apply()


import asyncio
import os
import random
import time
from functools import reduce
from typing import Any, Dict, List, Literal

from fake_useragent import UserAgent
from playwright.async_api import async_playwright


import pandas





ua = UserAgent()

VIEWPORT_WIDTH_RANGE = (1000, 1920)
VIEWPORT_HEIGHT_RANGE = (800, 1080)
LOCALS = ["pt-BR", "pt-PT", "es-AR", "es-UY", "es-PY"]
TIMEZONES = [
    "America/Sao_Paulo",
    "America/Rio_Branco",
    "America/Manaus",
    "America/Fortaleza",
    "America/Recife",
    "America/Argentina/Buenos_Aires",
    "America/Montevideo",
]

MOUSE_SCROLL_MOVES_RANGE = (3, 7)
MOUSE_SCROLL_WHEEL_MOVES_RANGE = (100, 500)
MOUSE_SCROLL_MOVE_SLEEP_RANGE = (0.1, 0.50)

MOUSE_TRANSLATE_MOVES_RANGE = (3, 8)
MOUSE_TRANSLATE_WHEEL_MOVES_RANGE = (100, 500)
MOUSE_TRANSLATE_MOVE_SLEEP_RANGE = (0.1, 0.50)

PROXIES_FILE = "proxies.txt"


def get_masked_proxy(proxy_config):
    """Exibe configuração do proxy ocultando informações sensíveis"""
    server = proxy_config.get("server", "N/A")
    username = proxy_config.get("username", "N/A")
    password = proxy_config.get("password", "N/A")

    # Mascara o IP mantendo apenas os primeiros octetos
    def mask_server(server_url):
        import re

        # Substitui os dois últimos octetos do IP por ***
        return re.sub(r"(\d+\.\d+\.)\d+\.\d+", r"\1***.***", server_url)

    safe_server = mask_server(server) if server != "N/A" else "N/A"
    safe_username = (
        username[:3] + "*" * max(0, len(username) - 3) if username != "N/A" else "N/A"
    )
    safe_password = "*" * len(password) if password != "N/A" else "N/A"

    proxy_url = (
        f"http://{safe_username}:{safe_password}@{safe_server.replace('http://', '')}"
    )

    return proxy_url


async def set_chromium(playwright, headless=True, proxy=None):

    browser_opts = dict(headless=headless)

    if proxy:
        print(f"using proxy {get_masked_proxy(proxy)}")
        browser_opts.update(dict(proxy=proxy))

    return await playwright.chromium.launch(
        args=[
            "--disable-blink-features=AutomationControlled",
            "--disable-features=IsolateOrigins,site-per-process",
            "--disable-dev-shm-usage",
            "--no-sandbox",
            "--disable-setuid-sandbox",
        ],
        **browser_opts,
    )


async def set_firefox(playwright, headless=True, proxy=None):

    browser_opts = dict(headless=headless)

    if proxy:
        print(f"using proxy {get_masked_proxy(proxy)}")
        browser_opts.update(dict(proxy=proxy))

    return await playwright.firefox.launch(
        firefox_user_prefs={
            "dom.webdriver.enabled": False,
            "privacy.resistFingerprinting": False,
            "browser.cache.disk.enable": True,
            "browser.cache.memory.enable": True,
        },
        args=["--disable-dev-shm-usage", "--no-sandbox"],
        **browser_opts,
    )


async def set_browser(
    playwright,
    engine: Literal["firefox", "chromium", "random"],
    headless: bool = True,
    proxy=None,
):

    browser_opts = dict(headless=headless)

    if proxy:
        browser_opts.update(dict(proxy=proxy))

    if engine == "random":
        engine = random.choice(["chromium", "firefox"])

    match engine:
        case "firefox":
            return await set_firefox(playwright, **browser_opts)
        case "chromium":
            return await set_chromium(playwright, **browser_opts)
        case _:
            raise ValueError(f"Engine {_} not recognized.")


async def set_context(browser):
    # Create a new browser context with random viewport size
    viewport_width = random.randint(*VIEWPORT_WIDTH_RANGE)
    viewport_height = random.randint(*VIEWPORT_HEIGHT_RANGE)

    return await browser.new_context(
        user_agent=ua.random,
        viewport={"width": viewport_width, "height": viewport_height},
        locale=random.choice(LOCALS),
        timezone_id=random.choice(TIMEZONES),
        permissions=["geolocation"],
        has_touch=random.choice([True, False]),
    )


async def set_page(context):

    page = await context.new_page()

    # Emulate human-like behavior by intercepting WebDriver calls
    await page.add_init_script(
        """
    Object.defineProperty(navigator, 'webdriver', {
        get: () => false
    });

    // Add plugins length
    Object.defineProperty(navigator, 'plugins', {
        get: () => [1, 2, 3, 4, 5]
    });

    // Overwrite the languages property
    Object.defineProperty(navigator, 'languages', {
        get: () => ['pt-BR', 'pt']
    });
    """
    )

    return page


async def do_movements(page):
    # Random scrolling behavior
    for _ in range(random.randint(*MOUSE_SCROLL_MOVES_RANGE)):
        await page.mouse.wheel(0, random.randint(*MOUSE_SCROLL_WHEEL_MOVES_RANGE))
        await asyncio.sleep(random.uniform(*MOUSE_SCROLL_MOVE_SLEEP_RANGE))

    # Random mouse movements
    for _ in range(random.randint(*MOUSE_TRANSLATE_MOVES_RANGE)):
        await page.mouse.move(
            random.randint(100, 1000 - 100),
            random.randint(100, 800 - 100),
            steps=random.randint(1, 4),
        )
        await asyncio.sleep(random.uniform(0.05, 0.1))


async def clear_headers(original_headers):
    """Limpa os headers mantendo apenas os campos necessários."""
    # Campos que consideramos necessários para a requisição
    necessary_fields = [
        "user-agent",
        "accept",
        "referer",
        "authorization",
        "origin",
        "host",
    ]

    # Cria um novo dicionário apenas com os campos necessários
    cleaned_headers = {
        k: v for k, v in original_headers.items() if k.lower() in necessary_fields
    }

    return cleaned_headers


async def perform_api_request(context, headers, endpoint):
    """Realiza uma requisição GET para o endpoint usando os headers fornecidos."""
    cleaned_headers = await clear_headers(headers)
    api_page = await set_page(context)
    try:
        response = await api_page.request.get(endpoint, headers=cleaned_headers)
        if response.ok:
            return await response.json()

        error_text = await response.text()
        print(f"Falha na requisição. Status: {response.status} | Erro: {error_text}")
        return None

    except Exception as e:
        print(f"Erro ao fazer a requisição: {str(e)}")
        return None
    finally:
        # Fecha a página da API
        await api_page.close()


import random


def get_proxy():
    with open(PROXIES_FILE, "r") as f:
        lines = f.readlines()

    line = random.choice(lines).strip()
    ip, port, user, password = line.split(":")

    return {"server": f"http://{ip}:{port}", "username": user, "password": password}


import httpx


async def test_proxy(proxy_config):
    """Testa se o proxy está funcionando com múltiplos endpoints"""

    # Mascara o IP mantendo apenas os primeiros octetos
    def mask_server(server_url):
        import re

        # Substitui os dois últimos octetos do IP por ***
        return re.sub(r"(\d+\.\d+\.)\d+\.\d+", r"\1***.***", server_url)

    proxy_url = f"http://{proxy_config['username']}:{proxy_config['password']}@{proxy_config['server'].replace('http://', '')}"

    # Lista de endpoints para testar
    test_endpoints = [
        "http://httpbin.org/ip",
        "http://ipinfo.io/json",
        "https://api.ipify.org?format=json",
    ]

    async with httpx.AsyncClient(
        proxy=proxy_url,  # Mudança aqui: proxy ao invés de proxies
        timeout=httpx.Timeout(10.0, connect=5.0),
    ) as client:

        for endpoint in test_endpoints:
            try:
                response = await client.get(endpoint)

                if response.status_code == 200:
                    result = response.json()
                    ip = result.get("origin") or result.get("ip")

                    safe_server = mask_server(ip) if ip != "N/A" else "N/A"

                    print(
                        f"Proxy funcionando. IP: {safe_server} (testado em {endpoint})"
                    )
                    return True
                else:
                    print(
                        f"Endpoint {endpoint} retornou status: {response.status_code}"
                    )

            except httpx.TimeoutException:
                print(f"Timeout no endpoint {endpoint}")
                continue
            except httpx.ProxyError as e:
                print(f"Erro de proxy no endpoint {endpoint}: {e}")
                continue
            except Exception as e:
                print(f"Erro no endpoint {endpoint}: {e}")
                continue

    print("Proxy não funcionou em nenhum endpoint testado")
    return False


from IPython.display import Image, display
import base64

def show_base64(base64_str: str):
    """Exibe uma imagem base64 no notebook Jupyter."""
    display(Image(data=base64.b64decode(base64_str)))



# import requests
# requests.get(
#     "https://ipv4.webshare.io/",
#     proxies={
#         "http": "http://emdemor415:0e1nsrk7929p@92.113.237.195:7279/",
#         "https": "http://emdemor415:0e1nsrk7929p@92.113.237.195:7279/"
#     }
# ).text


# proxy = {'server': 'http://92.113.237.195:7279', 'username': 'emdemor415', 'password': '0e1nsrk7929p'}


proxy = get_proxy()
print(get_masked_proxy(proxy))
await test_proxy(proxy)





import litellm

response = await litellm.acompletion(
    model="gpt-4o-mini",
    response_format={"type": "json_object"},
    messages=[
        {
            "role": "system",
            "content": "You are a helpful assistant designed to output JSON.",
        },
        {"role": "user", "content": "Who won the world series in 2020?"},
    ],
)

cost = litellm.completion_cost(completion_response=response)
print(response.choices[0].message.content)
print(f"Custo da requisição: R$ {5.5 * cost:.2f}")


import tokencost

costs = tokencost.calculate_all_costs_and_tokens(
    prompt="Explique machine learning",
    completion="Machine learning é...",
    model="gpt-4o-mini",
)

costs











import base64

# url = "https://descomplica.pocosdecaldas.mg.gov.br/"
url = "https://resende.rj.gov.br/blogtransparencia/page/index.asp"

proxy_config = get_proxy()

assert await test_proxy(proxy_config)

async with async_playwright() as playwright:
    browser = await set_browser(playwright, engine="random", proxy=proxy_config)
    context = await set_context(browser)
    page = await set_page(context)
    await page.goto(url, wait_until="networkidle")
    html_content = await page.content()

    screenshot_bytes = await page.screenshot(full_page=True, type="jpeg", quality=40)

    screenshot_base64 = base64.b64encode(screenshot_bytes).decode("utf-8")


from src.clear_html import clean_html_for_llm


cleaning_html = clean_html_for_llm(html_content, remove_classes=True)


len(cleaning_html['cleaned_html'])


# print(cleaning_html['cleaned_html'].replace("\n", ""))


from textwrap import dedent


def create_prompts(url, html_content, max_content_size: int = 50000):
    """
    Cria o prompt para P1: Identificação de Links Relevantes
    """

    system_prompt = dedent("""
    Você é um especialista em análise de portais de transparência governamental brasileiros. 
    Sua missão é ajudar a construir um agente de IA para coletar dados salariais de servidores públicos municipais.

    INSTRUÇÕES IMPORTANTES:
    1. Analise CUIDADOSAMENTE tanto a captura de tela quanto o código HTML fornecido
    2. Procure por links, botões ou menus que possam levar a informações sobre:
       - Transparência
       - Servidores públicos
       - Folha de pagamento
       - Salários e remuneração
       - Recursos humanos
       - Portal da transparência
       - Gastos públicos
       - Despesas com pessoal

    3. Considere variações regionais nos termos (ex: "funcionários", "colaboradores", "quadro de pessoal")
    4. Observe tanto elementos visuais óbvios quanto links menos evidentes no rodapé ou menus secundários
    5. Avalie a confiança baseada na clareza e relevância do link encontrado

    RESPONDA SEMPRE EM JSON VÁLIDO seguindo EXATAMENTE a estrutura especificada.""")

    user_prompt = dedent(f"""

    <main-question>
    Na página atual, existem links ou botões que levam para informações sobre servidores públicos, transparência, folha de pagamento ou salários?
    </main-question>

    URL ANALISADA: {url}

    CONTEXTO ADICIONAL:
    <context>
    - Esta é a homepage de um portal municipal brasileiro
    - Estamos buscando o caminho para acessar dados de remuneração de servidores públicos
    - Links podem estar em menus principais, rodapé, ou seções específicas de transparência
    </context>

    ANÁLISE REQUERIDA:
    <required-analysis>
    1. Examine a captura de tela para identificar elementos visuais relevantes
    2. Analise o HTML para encontrar links e estruturas de navegação
    3. Identifique termos-chave relacionados à transparência e servidores públicos
    4. Determine a localização e tipo de cada link encontrado
    5. Se o link encontrado for relativo, utilize a url da página para compor o link global
    </required-analysis>

    RESPONDA EM JSON SEGUINDO ESTA ESTRUTURA EXATA:
    <output-format>
    {{
      "tem_links_servidores": boolean,
      "links_encontrados": [
        {{
          "texto": "texto exato do link/botão",
          "url": "URL relativa ou absoluta",
          "tipo": "link_principal|menu_dropdown|botao|rodape|sidebar|breadcrumb",
          "confianca": float_entre_0_e_1,
          "justificativa": "breve explicação do por que este link é relevante",
          "posicao_visual": "descrição da localização na página"
        }}
      ],
      "termos_identificados": ["lista", "de", "termos", "relevantes", "encontrados"],
      "localizacao_na_pagina": "menu_superior|sidebar|centro|rodape|multiplas_localizacoes",
      "observacoes_adicionais": "qualquer observação importante sobre a estrutura do site",
      "necessita_javascript": boolean,
      "nivel_dificuldade_navegacao": "facil|medio|dificil"
    }}
    </output-format>

    CÓDIGO HTML DA PÁGINA:
    <page-html>
    {html_content[:max_content_size]}
    </page-html>

    <additional-important-information>
    IMPORTANTE: Se não encontrar links óbvios, procure por:
    - Menus que possam ter submenus
    - Links no rodapé
    - Seções como "Acesso à Informação" ou "LAI"
    - Ícones sem texto descritivo
    - Links em outras linguagens ou abreviações

    IMPORTANTE: os links relevantes deve começar com `http`. Links relativos não podem ser utilizados.
    </additional-important-information>
    """)

    return system_prompt, user_prompt


system_prompt, user_prompt = create_prompts(url, cleaning_html['cleaned_html'].replace("\n", ""))


with open("teste.html", "w") as f:
    f.write(html_content)


# print(user_prompt)


from openai import OpenAI

client = OpenAI(
    api_key=os.environ["DEEPSEEK_API_KEY"], base_url="https://api.deepseek.com"
)

response = client.chat.completions.create(
    model="deepseek-chat",
    messages=[
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ],
    stream=False,
)

print(response.choices[0].message.content)





import litellm

response = await litellm.acompletion(
    model="gpt-4o-mini",
    response_format={"type": "json_object"},
    messages=[
        {
            "role": "system",
            "content": system_prompt,
        },
        {"role": "user", "content": user_prompt},
    ],
)

cost = litellm.completion_cost(completion_response=response)
print(response.choices[0].message.content)
print(f"Custo da requisição: R$ {5.5 * cost:.4f}")


import litellm

response = await litellm.acompletion(
    model="deepseek/deepseek-chat",
    response_format={"type": "json_object"},
    messages=[
        {
            "role": "system",
            "content": system_prompt,
        },
        {"role": "user", "content": user_prompt},
    ],
)

cost = litellm.completion_cost(completion_response=response)
print(response.choices[0].message.content)
print(f"Custo da requisição: R$ {5.5 * cost:.4f}")





cost


import tokencost

costs = tokencost.calculate_all_costs_and_tokens(
    prompt=system_prompt+user_prompt,
    completion=response.choices[0].message.content,
    model="gpt-4o-mini",a
)

costs




















# show_base64(screenshot_base64)


from pydantic import BaseModel

city = "Poços de Caldas"
uf = "MG"

history = [
    {
        "type": "contexto",
        "message": (f"O usuário jé se apresentou a você lhe informou o seu objetivo"),
    },
    {
        "type": "contexto",
        "message": "O usuário ja lhe forneceu a url da página principal",
    },
    {
        "type": "seu pensamento",
        "message": '"Preciso definir se tem algum link interessante nessa página que me leve a uma outra página onde terei a tabela com a relação nominal de salário. "',
    },
]


formatted_history = "\n".join(
    [f"Step {i+1}: [{x['type']}] {x['message']}" for i, x in enumerate(history)]
)

prompt = f"""
<objetivo>
Encontrar uma forma de obter o salário nominal de cada uma dos servidores públicos da cidade de {city} - {uf}
</objetivo>

<sua-tarefa>
Verfique no html da página se existem links relevantes que leval a outras páginas onde possivelmente
poderei encontrar a relação entre nome e salário dos servidores públicos da cidade de {city} - {uf}.
</sua-tarefa>

<html-da-pagina>
{html}
</html-da-pagina>

<history>
{formatted_history}
</history>
"""


class LLMCompletion(BaseModel):
    relevant_links: list[str]


# print(prompt)


costs = tokencost.calculate_all_costs_and_tokens(
    prompt=formatted_history, completion="", model="gpt-4o-mini"
)

costs





import litellm

response = await litellm.acompletion(
    model="gpt-4o-mini",
    response_format=LLMCompletion,
    messages=[
        {
            "role": "system",
            "content": "Você é um assistente especialista em navegação web.",
        },
        {"role": "user", "content": prompt},
    ],
)

cost = litellm.completion_cost(completion_response=response)
print(response.choices[0].message.content)
print(f"Custo da requisição: R$ {5.5 * cost:.2f}")


url = "https://descomplica.pocosdecaldas.mg.gov.br"

proxy_config = get_proxy()

assert await test_proxy(proxy_config)

async with async_playwright() as playwright:
    browser = await set_browser(playwright, engine="random", proxy=proxy_config)
    context = await set_context(browser)
    page = await set_page(context)
    await page.goto(url, wait_until="networkidle")
    html = await page.content()

response = await litellm.acompletion(
    model="gpt-4o-mini",
    response_format=LLMCompletion,
    messages=[
        {
            "role": "system",
            "content": "Você é um assistente especialista em navegação web.",
        },
        {"role": "user", "content": prompt},
    ],
)

cost = litellm.completion_cost(completion_response=response)
print(response.choices[0].message.content)
print(f"Custo da requisição: R$ {5.5 * cost:.2f}")



































# print(html)


proxy_config = get_proxy()
print_proxy_safe(proxy_config)








import os


from openai import OpenAI

client = OpenAI(
    api_key=os.environ["DEEPSEEK_API_KEY"], base_url="https://api.deepseek.com"
)

response = client.chat.completions.create(
    model="deepseek-chat",
    messages=[
        {"role": "system", "content": "You are a helpful assistant"},
        {"role": "user", "content": "Hello"},
    ],
    stream=False,
)

print(response.choices[0].message.content)

















get_ipython().getoutput("pip install browser-use -qqq")


import asyncio
import os

from browser_use import Agent
from browser_use.llm import ChatOpenAI

llm = ChatOpenAI(
    base_url="https://api.deepseek.com/v1",  # ou sua instância local
    api_key=os.environ["DEEPSEEK_API_KEY"],
    model="deepseek-v3",
)

# llm = ChatOpenAI(
#     api_key=os.environ["OPENAI_API_KEY"],
#     model="gpt-4o-mini",
# )

agent = Agent(
    task="encontre o link para a pagia onde eu consiga encontrar o salário dos servidores públicos municipais da cidade de resende-rj",
    llm=llm,
)
await agent.run()











import asyncio
import json

from browser_use import Agent
from browser_use.llm import ChatOpenAI

llm = ChatOpenAI(
    base_url="https://api.deepseek.com/v1",  # ou sua instância local
    api_key=chave_deepseek,
    model="deepseek-v3",
)

agent = Agent(
    task="""
    Acesse o Google, busque por "melhores frameworks Python para IA em 2025".
    Extraia os 5 primeiros resultados com:
    - Título da página
    - Link da página
    - Um pequeno resumo (1-2 frases)

    Formate o resultado assim:
    [
      {
        "title": "Título da página",
        "url": "https://...",
        "summary": "Resumo do conteúdo"
      },
      ...
    ]
    Só responda com o JSON. Não inclua nenhuma explicação.
    """,
    llm=llm,
)

result = await agent.run()
print("RESULTADO:\n")
try:
    parsed = json.loads(result)
    for i, item in enumerate(parsed, 1):
        print(f"{i}. {item['title']}")
        print(f"   URL: {item['url']}")
        print(f"   RESUMO: {item['summary']}\n")
except Exception as e:
    print("Não foi possível converter para JSON:\n")
    print(result)





import asyncio
import json

from browser_use import Agent
from browser_use.llm import ChatOpenAI


async def main():
    agent = Agent(
        task="""
        Acesse o Google, busque por "melhores frameworks Python para IA em 2025".
        Extraia os 5 primeiros resultados com:
        - Título da página
        - Link da página
        - Um pequeno resumo (1-2 frases)

        Formate o resultado assim:
        [
          {
            "title": "Título da página",
            "url": "https://...",
            "summary": "Resumo do conteúdo"
          },
          ...
        ]
        Só responda com o JSON. Não inclua nenhuma explicação.
        """,
        llm=ChatOpenAI(model="gpt-4o", temperature=0.3),
    )

    result = await agent.run()
    print("RESULTADO:\n")
    try:
        parsed = json.loads(result)
        for i, item in enumerate(parsed, 1):
            print(f"{i}. {item['title']}")
            print(f"   URL: {item['url']}")
            print(f"   RESUMO: {item['summary']}\n")
    except Exception as e:
        print("Não foi possível converter para JSON:\n")
        print(result)


asyncio.run(main())





page


url = "https://www.bing.com/search?q=portal+de+transparencia+resende"

async with async_playwright() as playwright:
    browser = await set_browser(playwright, engine="random")
    context = await set_context(browser)
    page = await set_page(context)

    try:
        print("Navegar para o Google")
        await page.goto(url, wait_until="networkidle")

        print("Pegar conteúdo da página")
        html_page = await page.content()

        # print("Aguardar o campo de busca aparecer e clicar nele")
        # search_input = page.locator('input[name="q"]')
        # await search_input.wait_for(state="visible")

        # print("Digitar a consulta")
        # await search_input.fill(query)

        # print("Pressionar Enter ou clicar no botão de busca")
        # await search_input.press("Enter")

        # print("Aguardar os resultados carregarem")
        # await page.wait_for_selector('#search', timeout=10000)

        # print("Aguardar um pouco mais para garantir que todos os resultados carregaram")
        # await page.wait_for_timeout(2000)

        # print("Coletar os resultados de busca")

    except Exception as e:
        print(f"Erro durante a busca: {e}")

    finally:
        await browser.close()


html_page

















# TÉCNICAS AVANÇADAS PARA EVITAR DETECÇÃO

# 1. HUMANIZAÇÃO EXTREMA
import asyncio
import math
import random


async def human_mouse_movement(page, start_x, start_y, end_x, end_y):
    """Simula movimento de mouse humano com curvas naturais"""

    steps = random.randint(15, 25)

    for i in range(steps):
        progress = i / steps

        # Curva Bézier para movimento natural
        control_x = start_x + random.uniform(-50, 50)
        control_y = start_y + random.uniform(-50, 50)

        # Calcular posição atual
        current_x = (
            (1 - progress) ** 2 * start_x
            + 2 * (1 - progress) * progress * control_x
            + progress**2 * end_x
        )
        current_y = (
            (1 - progress) ** 2 * start_y
            + 2 * (1 - progress) * progress * control_y
            + progress**2 * end_y
        )

        # Adicionar pequenas variações
        current_x += random.uniform(-2, 2)
        current_y += random.uniform(-2, 2)

        await page.mouse.move(current_x, current_y)
        await asyncio.sleep(random.uniform(0.01, 0.03))


async def human_typing(page, element, text):
    """Digitação com padrões humanos realistas"""

    await element.click()
    await asyncio.sleep(random.uniform(0.1, 0.3))

    for i, char in enumerate(text):
        # Velocidade variável (mais lento no início, mais rápido depois)
        base_delay = 0.12 if i < 3 else 0.08

        # Caracteres especiais demoram mais
        if char in " -_@.":
            delay = base_delay * random.uniform(1.5, 2.5)
        else:
            delay = base_delay * random.uniform(0.7, 1.3)

        # Pequena chance de pausar (pensando)
        if random.random() < 0.05:
            delay += random.uniform(0.5, 1.5)

        await element.type(char)
        await asyncio.sleep(delay)


# 2. BROWSER FINGERPRINTING AVANÇADO
async def setup_realistic_browser(playwright):
    """Configura browser com fingerprint extremamente realista"""

    # Fingerprints reais coletados de browsers verdadeiros
    realistic_configs = [
        {
            "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "viewport": {"width": 1920, "height": 1080},
            "screen": {"width": 1920, "height": 1080},
            "timezone": "America/Sao_Paulo",
            "locale": "pt-BR",
            "platform": "Win32",
        },
        {
            "user_agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "viewport": {"width": 1440, "height": 900},
            "screen": {"width": 1440, "height": 900},
            "timezone": "America/Sao_Paulo",
            "locale": "pt-BR",
            "platform": "MacIntel",
        },
    ]

    config = random.choice(realistic_configs)

    browser = await playwright.chromium.launch(
        headless=True,
        args=[
            "--no-sandbox",
            "--disable-setuid-sandbox",
            "--disable-dev-shm-usage",
            "--disable-blink-features=AutomationControlled",
            "--exclude-switches=enable-automation",
            "--disable-extensions",
            "--disable-plugins-discovery",
            "--disable-plugins",
            "--disable-preconnect",
            "--disable-gpu",
            "--no-first-run",
            "--no-service-autorun",
            "--password-store=basic",
            "--system-developer-mode",
            "--mute-audio",
            "--no-zygote",
            "--no-default-browser-check",
            "--disable-backgrounding-occluded-windows",
            "--disable-renderer-backgrounding",
            "--disable-features=TranslateUI",
            "--disable-ipc-flooding-protection",
            f'--window-size={config["viewport"]["width"]},{config["viewport"]["height"]}',
        ],
    )

    context = await browser.new_context(
        user_agent=config["user_agent"],
        viewport=config["viewport"],
        screen=config["screen"],
        locale=config["locale"],
        timezone_id=config["timezone"],
        permissions=["geolocation"],
        geolocation={"latitude": -22.4609, "longitude": -44.4444},  # Resende, RJ
        extra_http_headers={
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Accept-Language": "pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7",
            "Cache-Control": "max-age=0",
            "Sec-Ch-Ua": '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            "Sec-Ch-Ua-Mobile": "?0",
            "Sec-Ch-Ua-Platform": f'"{config["platform"]}"',
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Sec-Fetch-User": "?1",
            "Upgrade-Insecure-Requests": "1",
        },
    )

    return browser, context


# 3. STEALTH SCRIPTS AVANÇADOS
ADVANCED_STEALTH_SCRIPT = """
(() => {
    // 1. Remover propriedades de automação
    delete navigator.__proto__.webdriver;
    delete navigator.webdriver;
    
    // 2. Mockear propriedades ausentes
    Object.defineProperty(navigator, 'webdriver', {
        get: () => undefined,
        configurable: true
    });
    
    // 3. Simular plugins reais
    Object.defineProperty(navigator, 'plugins', {
        get: () => [
            {
                0: {type: "application/x-google-chrome-pdf", suffixes: "pdf", description: "Portable Document Format", enabledPlugin: Plugin},
                description: "Portable Document Format",
                filename: "internal-pdf-viewer",
                length: 1,
                name: "Chrome PDF Plugin"
            },
            {
                0: {type: "application/pdf", suffixes: "pdf", description: "Portable Document Format", enabledPlugin: Plugin},
                description: "Portable Document Format", 
                filename: "mhjfbmdgcfjbbpaeojofohoefgiehjai",
                length: 1,
                name: "Chrome PDF Viewer"
            }
        ]
    });
    
    // 4. Simular propriedades de hardware
    Object.defineProperty(navigator, 'hardwareConcurrency', {
        get: () => 8
    });
    
    Object.defineProperty(navigator, 'deviceMemory', {
        get: () => 8
    });
    
    // 5. Mockear WebGL fingerprint
    const getParameter = WebGLRenderingContext.getParameter;
    WebGLRenderingContext.prototype.getParameter = function(parameter) {
        if (parameter === 37445) {
            return 'NVIDIA Corporation';
        }
        if (parameter === 37446) {
            return 'NVIDIA GeForce GTX 1060 6GB/PCIe/SSE2';
        }
        return getParameter(parameter);
    };
    
    // 6. Mockear screen properties
    Object.defineProperty(screen, 'availWidth', {
        get: () => window.screen.width
    });
    
    Object.defineProperty(screen, 'availHeight', {
        get: () => window.screen.height - 40  // Taskbar
    });
    
    // 7. Adicionar propriedades do Chrome ausentes
    if (!window.chrome) {
        window.chrome = {
            app: {
                isInstalled: false,
                InstallState: {
                    DISABLED: 'disabled',
                    INSTALLED: 'installed',
                    NOT_INSTALLED: 'not_installed'
                },
                RunningState: {
                    CANNOT_RUN: 'cannot_run',
                    READY_TO_RUN: 'ready_to_run',
                    RUNNING: 'running'
                }
            },
            runtime: {
                OnInstalledReason: {
                    CHROME_UPDATE: 'chrome_update',
                    INSTALL: 'install',
                    SHARED_MODULE_UPDATE: 'shared_module_update',
                    UPDATE: 'update'
                },
                OnRestartRequiredReason: {
                    APP_UPDATE: 'app_update',
                    OS_UPDATE: 'os_update',
                    PERIODIC: 'periodic'
                },
                PlatformArch: {
                    ARM: 'arm',
                    ARM64: 'arm64',
                    MIPS: 'mips',
                    MIPS64: 'mips64',
                    X86_32: 'x86-32',
                    X86_64: 'x86-64'
                },
                PlatformNaclArch: {
                    ARM: 'arm',
                    MIPS: 'mips',
                    MIPS64: 'mips64',
                    X86_32: 'x86-32',
                    X86_64: 'x86-64'
                },
                PlatformOs: {
                    ANDROID: 'android',
                    CROS: 'cros',
                    FREEBSD: 'freebsd',
                    LINUX: 'linux',
                    MAC: 'mac',
                    OPENBSD: 'openbsd',
                    WIN: 'win'
                },
                RequestUpdateCheckStatus: {
                    NO_UPDATE: 'no_update',
                    THROTTLED: 'throttled',
                    UPDATE_AVAILABLE: 'update_available'
                }
            }
        };
    }
    
    // 8. Remover automation flags
    Object.defineProperty(navigator, 'languages', {
        get: () => ['pt-BR', 'pt', 'en-US', 'en']
    });
    
    // 9. Simular permissions reais
    const originalQuery = window.navigator.permissions.query;
    window.navigator.permissions.query = (parameters) => (
        parameters.name === 'notifications' ?
            Promise.resolve({ state: Notification.permission }) :
            originalQuery(parameters)
    );
    
    // 10. Adicionar event listeners naturais
    ['mousedown', 'mouseup', 'click', 'mousemove'].forEach(eventType => {
        document.addEventListener(eventType, () => {}, true);
    });
    
})();
"""


# 4. FUNÇÃO PRINCIPAL COM TODAS AS TÉCNICAS
async def ultimate_stealth_search(query):
    """Busca com técnicas stealth de última geração"""

    async with async_playwright() as playwright:
        browser, context = await setup_realistic_browser(playwright)
        page = await context.new_page()

        # Aplicar script stealth
        await page.add_init_script(ADVANCED_STEALTH_SCRIPT)

        try:
            print("🕵️ Iniciando busca stealth de última geração...")

            # Navegar com comportamento humano
            await page.goto("https://www.google.com.br")
            await asyncio.sleep(random.uniform(2, 4))

            # Simular comportamento de usuário real
            await page.mouse.move(100, 100)
            await asyncio.sleep(0.5)

            # Scroll para baixo e para cima (comportamento natural)
            await page.mouse.wheel(0, 200)
            await asyncio.sleep(0.5)
            await page.mouse.wheel(0, -100)
            await asyncio.sleep(1)

            # Encontrar campo de busca
            search_box = page.locator('input[name="q"]').first
            await search_box.wait_for(state="visible")

            # Movimento natural do mouse até o campo
            box = await search_box.bounding_box()
            if box:
                await human_mouse_movement(
                    page,
                    random.randint(100, 300),
                    random.randint(100, 300),
                    box["x"] + box["width"] / 2,
                    box["y"] + box["height"] / 2,
                )

            # Digitação humana
            await human_typing(page, search_box, query)

            # Pausa antes de pressionar Enter
            await asyncio.sleep(random.uniform(0.5, 1.5))
            await search_box.press("Enter")

            # Aguardar com comportamento natural
            await asyncio.sleep(random.uniform(3, 6))

            # Verificar se chegaram resultados
            try:
                await page.wait_for_selector(".g, #search", timeout=10000)
                print("✅ Resultados carregados com sucesso!")

                # Coletar resultados (mesmo código anterior)
                results = []
                search_results = await page.query_selector_all(".g")

                for i, result in enumerate(search_results[:10]):
                    try:
                        title_el = await result.query_selector("h3")
                        title = (
                            await title_el.inner_text() if title_el else "Sem título"
                        )

                        url_el = await result.query_selector("a")
                        url = (
                            await url_el.get_attribute("href") if url_el else "Sem URL"
                        )

                        snippet_el = await result.query_selector(".VwiC3b, .s3v9rd")
                        snippet = (
                            await snippet_el.inner_text()
                            if snippet_el
                            else "Sem snippet"
                        )

                        if title != "Sem título" and url != "Sem URL":
                            results.append(
                                {
                                    "position": i + 1,
                                    "title": title.strip(),
                                    "url": url,
                                    "snippet": snippet.strip(),
                                }
                            )

                    except Exception:
                        continue

                return results

            except:
                # Verificar se foi bloqueado
                captcha = await page.query_selector("#recaptcha, .g-recaptcha")
                if captcha:
                    print("❌ Ainda detectado como bot")
                else:
                    print("❌ Timeout nos resultados")
                return None

        finally:
            await browser.close()


# 5. EXEMPLO DE USO
async def main():
    query = "portal de transparência de Resende - RJ"
    results = await ultimate_stealth_search(query)

    if results:
        print(f"\n🎉 SUCESSO! {len(results)} resultados obtidos")
        for r in results[:3]:
            print(f"• {r['title']}")
    else:
        print("❌ Ainda não foi possível burlar a detecção")


if __name__ == "__main__":
    asyncio.run(main())









