get_ipython().run_line_magic("load_ext", " autoreload")
get_ipython().run_line_magic("autoreload", " 2")

import nest_asyncio

nest_asyncio.apply()


import base64
import json

from playwright.async_api import async_playwright
from src.browser import set_browser, set_context, set_page
from src.clear_html import clean_html_for_llm
from src.prompts.homepage_check import ResultadoBuscaServidores, check_homepage
from src.proxies import get_masked_proxy, get_proxy, test_proxy








import asyncio

from src.browser import navigate_with_retry

# Código principal modificado
url = "https://descomplica.pocosdecaldas.mg.gov.br/info.php?c=68"
# url = "https://resende.rj.gov.br/blogtransparencia/page/index.asp"

proxy_config = get_proxy()
assert await test_proxy(proxy_config)

async with async_playwright() as playwright:
    browser = await set_browser(playwright, engine="random", proxy=proxy_config)
    context = await set_context(browser)
    page = await set_page(context)

    await navigate_with_retry(page, url)

    await asyncio.sleep(3)

    html_content = await page.content()
    screenshot_bytes = await page.screenshot(full_page=True, type="jpeg", quality=40)
    screenshot_base64 = base64.b64encode(screenshot_bytes).decode("utf-8")

response = await check_homepage(url, html_content)
print(f"Custo = {response.cost_brl}")
parsed_response = ResultadoBuscaServidores(
    **json.loads(response.choices[0].message.content)
)


import json

print(parsed_response.model_dump_json(indent=4))


response = await check_homepage(url, html_content, model="gpt-4o")
print(f"Custo = {response.cost_brl}")
parsed_response = ResultadoBuscaServidores(
    **json.loads(response.choices[0].message.content)
)
print(parsed_response.model_dump_json(indent=4))


response = await check_homepage(url, html_content, model="gemini/gemini-1.5-flash")
print(f"Custo = {response.cost_brl}")
parsed_response = ResultadoBuscaServidores(
    **json.loads(response.choices[0].message.content)
)


parsed_response


response = await check_homepage(url, html_content, model="gemini/gemini-2.0-flash")
print(f"Custo = {response.cost_brl}")
parsed_response = ResultadoBuscaServidores(
    **json.loads(response.choices[0].message.content)
)


response = await check_homepage(url, html_content, model="gemini/gemini-2.5-flash")
print(f"Custo = {response.cost_brl}")
parsed_response = ResultadoBuscaServidores(
    **json.loads(response.choices[0].message.content)
)


response = await check_homepage(url, html_content, model="gemini/gemini-2.5-pro")
print(f"Custo = {response.cost_brl}")
parsed_response = ResultadoBuscaServidores(
    **json.loads(response.choices[0].message.content)
)











import base64
import io

import google.generativeai as genai
from PIL import Image


def analisar_imagem_base64(base64_string, prompt):
    image_bytes = base64.b64decode(base64_string)
    image = Image.open(io.BytesIO(image_bytes))
    model = genai.GenerativeModel("gemini-2.5-pro")
    response = model.generate_content([prompt, image])
    return response.text


analisar_imagem_base64(screenshot_base64, "qual a cor predominante?")





import os

import litellm


def analisar_imagem_litellm(
    base64_string,
    prompt="Descreva esta imagem",
    brl_currency: float = 5.6,
    model: str = "gemini/gemini-2.5-flash",
):
    messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{base64_string}"},
                },
            ],
        }
    ]

    response = litellm.completion(model=model, messages=messages, max_tokens=1000)

    cost = litellm.completion_cost(model=model, completion_response=response)

    print(f"Custo BRL = R$ {brl_currency * cost}")

    return response.choices[0].message.content


analisar_imagem_litellm(screenshot_base64, "qual a cor predominante?")


analisar_imagem_litellm(
    screenshot_base64, "qual a cor predominante?", model="gemini/gemini-2.5-pro"
)


from src.scrape_tools import show_base64

show_base64(screenshot_base64)


response = await check_homepage(
    url,
    html_content,
    model="deepseek/deepseek-chat",
    response_format={"type": "json_object"},
)
print(f"Custo = {response.cost_brl}")
parsed_response = ResultadoBuscaServidores(
    **json.loads(response.choices[0].message.content)
)
print(parsed_response)

from src.scrape_tools import show_base64

show_base64(screenshot_base64)


json.loads(response.choices[0].message.content)


parsed_response.links_encontrados[0].justificativa


response = await check_homepage(url, html_content)
print(f"Custo = {response.cost_brl}")

parsed_response = ResultadoBuscaServidores(
    **json.loads(response.choices[0].message.content)
)


parsed_response


url = "https://descomplica.pocosdecaldas.mg.gov.br/info.php?c=68"


proxy_config = get_proxy()

assert await test_proxy(proxy_config)

async with async_playwright() as playwright:
    browser = await set_browser(playwright, engine="random", proxy=proxy_config)
    context = await set_context(browser)
    page = await set_page(context)
    await page.goto(url, wait_until="networkidle", timeout=60000)
    html_content = await page.content()

    screenshot_bytes = await page.screenshot(full_page=True, type="jpeg", quality=40)

    screenshot_base64 = base64.b64encode(screenshot_bytes).decode("utf-8")

response = await check_homepage(url, html_content)
print(f"Custo = {response.cost_brl}")

parsed_response = ResultadoBuscaServidores(
    **json.loads(response.choices[0].message.content)
)
print(f"Parecer: {parsed_response.parecer}")


with open("teste.html", "w") as f:
    f.write(html_content)


from src.scrape_tools import show_base64

show_base64(screenshot_base64)


response = await check_homepage(url, html_content, model="deepseek/deepseek-chat")
print(f"Custo = {response.cost_brl}")

# parsed_response = ResultadoBuscaServidores(**json.loads(response.choices[0].message.content))
# print(f"Parecer: {parsed_response.parecer}")





url = "https://descomplica.pocosdecaldas.mg.gov.br/info.php?c=26"
# url = "https://resende.rj.gov.br/blogtransparencia/page/index.asp"

proxy_config = get_proxy()

assert await test_proxy(proxy_config)

async with async_playwright() as playwright:
    browser = await set_browser(playwright, engine="random", proxy=proxy_config)
    context = await set_context(browser)
    page = await set_page(context)
    await page.goto(url, wait_until="networkidle")
    html_content = await page.content()

    screenshot_bytes = await page.screenshot(full_page=True, type="jpeg", quality=40)

    screenshot_base64 = base64.b64encode(screenshot_bytes).decode("utf-8")


response = await check_homepage(url, html_content)


ResultadoBuscaServidores(**json.loads(response.choices[0].message.content))








import asyncio
import os
import random
import time
from functools import reduce
from typing import Any, Dict, List, Literal

from fake_useragent import UserAgent
from playwright.async_api import async_playwright


import pandas





import asyncio

from src.browser import navigate_with_retry

url = "https://transparencia.betha.cloud/#/"

proxy_config = get_proxy()
assert await test_proxy(proxy_config)

responses_list = []

def handle_response(response):
    condition = (
        (response.status == 200)
        & (response.url[-3:] != ".js")
        & (response.url[-4:] != ".css")
        & (response.url[-4:] != ".ttf")
        & (response.url[-4:] != ".svg")
        & (response.url[-4:] != ".png")
        & (response.url[-4:] != ".jpg")
        & (".js?" not in response.url)
        & (".woff" not in response.url)
    )

    if condition:
        responses_list.append(response)

async with async_playwright() as playwright:
    browser = await set_browser(playwright, engine="firefox", proxy=proxy_config)
    context = await set_context(browser)
    page = await set_page(context)

    page.on("response", handle_response)

    await navigate_with_retry(page, url)


responses_list


def handle_response(response):
    condition = (
        (response.status == 200)
        & (response.url[-3:] != ".js")
        & (response.url[-4:] != ".css")
        & (response.url[-4:] != ".ttf")
        & (response.url[-4:] != ".svg")
        & (response.url[-4:] != ".png")
        & (response.url[-4:] != ".jpg")
        & (".js?" not in response.url)
        & (".woff" not in response.url)
    )

    if condition:
        responses_list.append(response)





from src.proxies import get_masked_proxy, get_proxy, test_proxy

proxy = get_proxy()
print(get_masked_proxy(proxy))
await test_proxy(proxy)





import litellm

response = await litellm.acompletion(
    model="gpt-4o-mini",
    response_format={"type": "json_object"},
    messages=[
        {
            "role": "system",
            "content": "You are a helpful assistant designed to output JSON.",
        },
        {"role": "user", "content": "Who won the world series in 2020?"},
    ],
)

cost = litellm.completion_cost(completion_response=response)
print(response.choices[0].message.content)
print(f"Custo da requisição: R$ {5.5 * cost:.2f}")


import tokencost

costs = tokencost.calculate_all_costs_and_tokens(
    prompt="Explique machine learning",
    completion="Machine learning é...",
    model="gpt-4o-mini",
)

costs











import base64

from src.browser import set_browser, set_context, set_page
from src.clear_html import clean_html_for_llm

url = "https://descomplica.pocosdecaldas.mg.gov.br/"
# url = "https://resende.rj.gov.br/blogtransparencia/page/index.asp"

proxy_config = get_proxy()

assert await test_proxy(proxy_config)

async with async_playwright() as playwright:
    browser = await set_browser(playwright, engine="random", proxy=proxy_config)
    context = await set_context(browser)
    page = await set_page(context)
    await page.goto(url, wait_until="networkidle")
    html_content = await page.content()

    screenshot_bytes = await page.screenshot(full_page=True, type="jpeg", quality=40)

    screenshot_base64 = base64.b64encode(screenshot_bytes).decode("utf-8")


from src.prompts.homepage_check import check_homepage

response = await check_homepage(url, html_content)

import json

ResultadoBuscaServidores(**json.loads(response.choices[0].message.content))











from src.clear_html import clean_html_for_llm


cleaning_html = clean_html_for_llm(html_content, remove_classes=True)


len(cleaning_html["cleaned_html"])


# print(cleaning_html['cleaned_html'].replace("\n", ""))


from textwrap import dedent


def create_prompts(url, html_content, max_content_size: int = 50000):
    """
    Cria o prompt para P1: Identificação de Links Relevantes
    """

    system_prompt = dedent(
        """
    Você é um especialista em análise de portais de transparência governamental brasileiros. 
    Sua missão é ajudar a construir um agente de IA para coletar dados salariais de servidores públicos municipais.

    INSTRUÇÕES IMPORTANTES:
    1. Analise CUIDADOSAMENTE tanto a captura de tela quanto o código HTML fornecido
    2. Procure por links, botões ou menus que possam levar a informações sobre:
       - Transparência
       - Servidores públicos
       - Folha de pagamento
       - Salários e remuneração
       - Recursos humanos
       - Portal da transparência
       - Gastos públicos
       - Despesas com pessoal

    3. Considere variações regionais nos termos (ex: "funcionários", "colaboradores", "quadro de pessoal")
    4. Observe tanto elementos visuais óbvios quanto links menos evidentes no rodapé ou menus secundários
    5. Avalie a confiança baseada na clareza e relevância do link encontrado

    RESPONDA SEMPRE EM JSON VÁLIDO seguindo EXATAMENTE a estrutura especificada."""
    )

    user_prompt = dedent(
        f"""

    <main-question>
    Na página atual, existem links ou botões que levam para informações sobre servidores públicos, transparência, folha de pagamento ou salários?
    </main-question>

    URL ANALISADA: {url}

    CONTEXTO ADICIONAL:
    <context>
    - Esta é a homepage de um portal municipal brasileiro
    - Estamos buscando o caminho para acessar dados de remuneração de servidores públicos
    - Links podem estar em menus principais, rodapé, ou seções específicas de transparência
    </context>

    ANÁLISE REQUERIDA:
    <required-analysis>
    1. Examine a captura de tela para identificar elementos visuais relevantes
    2. Analise o HTML para encontrar links e estruturas de navegação
    3. Identifique termos-chave relacionados à transparência e servidores públicos
    4. Determine a localização e tipo de cada link encontrado
    5. Se o link encontrado for relativo, utilize a url da página para compor o link global
    </required-analysis>

    RESPONDA EM JSON SEGUINDO ESTA ESTRUTURA EXATA:
    <output-format>
    {{
      "tem_links_servidores": boolean,
      "links_encontrados": [
        {{
          "texto": "texto exato do link/botão",
          "url": "URL relativa ou absoluta",
          "tipo": "link_principal|menu_dropdown|botao|rodape|sidebar|breadcrumb",
          "confianca": float_entre_0_e_1,
          "justificativa": "breve explicação do por que este link é relevante",
          "posicao_visual": "descrição da localização na página"
        }}
      ],
      "termos_identificados": ["lista", "de", "termos", "relevantes", "encontrados"],
      "localizacao_na_pagina": "menu_superior|sidebar|centro|rodape|multiplas_localizacoes",
      "observacoes_adicionais": "qualquer observação importante sobre a estrutura do site",
      "necessita_javascript": boolean,
      "nivel_dificuldade_navegacao": "facil|medio|dificil"
    }}
    </output-format>

    CÓDIGO HTML DA PÁGINA:
    <page-html>
    {html_content[:max_content_size]}
    </page-html>

    <additional-important-information>
    IMPORTANTE: Se não encontrar links óbvios, procure por:
    - Menus que possam ter submenus
    - Links no rodapé
    - Seções como "Acesso à Informação" ou "LAI"
    - Ícones sem texto descritivo
    - Links em outras linguagens ou abreviações

    IMPORTANTE: os links relevantes deve começar com `http`. Links relativos não podem ser utilizados.
    </additional-important-information>
    """
    )

    return system_prompt, user_prompt


from enum import Enum
from typing import List, Literal, Optional

from pydantic import BaseModel, Field, HttpUrl


class TipoLink(str, Enum):
    """Tipos de links encontrados na página"""

    LINK_PRINCIPAL = "link_principal"
    MENU_DROPDOWN = "menu_dropdown"
    SUBMENU = "submenu"
    BOTAO = "botao"
    BANNER = "banner"


class LocalizacaoPagina(str, Enum):
    """Localização dos elementos na página"""

    TOPO = "topo"
    CENTRO = "centro"
    RODAPE = "rodape"
    LATERAL = "lateral"


class NivelDificuldade(str, Enum):
    """Nível de dificuldade para navegação"""

    FACIL = "facil"
    MEDIO = "medio"
    DIFICIL = "dificil"


class LinkEncontrado(BaseModel):
    """Modelo para um link encontrado na página"""

    texto: str = Field(..., description="Texto do link")
    url: str = Field(..., description="URL do link (pode ser relativa ou absoluta)")
    tipo: TipoLink = Field(..., description="Tipo do link encontrado")
    confianca: float = Field(
        ..., ge=0.0, le=1.0, description="Nível de confiança (0.0 a 1.0)"
    )
    justificativa: str = Field(
        ..., description="Justificativa para o nível de confiança"
    )
    posicao_visual: str = Field(
        ..., description="Descrição da posição visual do link na página"
    )


class ResultadoBuscaServidores(BaseModel):
    """Modelo principal para resultado da busca de links de servidores públicos"""

    tem_links_servidores: bool = Field(
        ..., description="Indica se foram encontrados links relacionados a servidores"
    )
    links_encontrados: List[LinkEncontrado] = Field(
        default_factory=list, description="Lista de links encontrados"
    )
    termos_identificados: List[str] = Field(
        default_factory=list, description="Termos relevantes identificados na página"
    )
    localizacao_na_pagina: LocalizacaoPagina = Field(
        ..., description="Localização principal dos links na página"
    )
    observacoes_adicionais: Optional[str] = Field(
        None, description="Observações adicionais sobre a busca"
    )
    necessita_javascript: bool = Field(
        False, description="Indica se é necessário JavaScript para acessar os links"
    )
    nivel_dificuldade_navegacao: NivelDificuldade = Field(
        ..., description="Nível de dificuldade para navegação"
    )

    class Config:
        """Configuração do modelo"""

        use_enum_values = True
        validate_assignment = True


import litellm

MODEL = "gpt-4o-mini"
BRL_CURRENCY = 5.6


def check_homepage(url, html_content):

    cleaning_html = clean_html_for_llm(html_content, remove_classes=True)

    system_prompt, user_prompt = create_prompts(
        url, cleaning_html["cleaned_html"].replace("\n", "")
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]

    response = await litellm.acompletion(
        model=MODEL,
        response_format=ResultadoBuscaServidores,
        messages=messages,
    )

    cost = litellm.completion_cost(model=MODEL, completion_response=response)

    setattr(response, "cost_usd", cost)
    setattr(response, "cost_brl", cost * BRL_CURRENCY)

    return response


setattr(response, "cost", 1)


response








import litellm

MODEL = "gpt-4o-mini"


async def check_homepage():

    messages = [
        {
            "role": "system",
            "content": system_prompt,
        },
        {"role": "user", "content": user_prompt},
    ]

    response = await litellm.acompletion(
        model=MODEL,
        response_format={"type": "json_object"},
        messages=messages,
    )

    cost = litellm.completion_cost(model=model, completion_response=response)
    print(response.choices[0].message.content)
    print(f"Custo da requisição: R$ {5.5 * cost:.4f}")


import litellm

model = "gpt-4o"
messages = [
    {
        "role": "system",
        "content": system_prompt,
    },
    {"role": "user", "content": user_prompt},
]

response = await litellm.acompletion(
    model=model,
    response_format={"type": "json_object"},
    messages=messages,
)

cost = litellm.completion_cost(model=model, completion_response=response)
print(response.choices[0].message.content)
print(f"Custo da requisição: R$ {5.5 * cost:.4f}")






































5.5 * litellm.completion_cost(model=model, completion_response=response, messages=[])


response


# from openai import OpenAI

# # Configurar cliente
# client = OpenAI(
#     api_key=os.environ["DEEPSEEK_API_KEY"],
#     base_url="https://api.deepseek.com"
# )


# response = client.chat.completions.parse(
#     model="deepseek-chat",
#     messages=[
#         {"role": "system", "content": "system_prompt"},
#         {"role": "user", "content": "user_prompt"},
#     ],
#     response_format=ResultadoBuscaServidores,
# )

# # Acessar o modelo parseado
# resultado = response.choices[0].message.parsed
# print("Modelo parseado com sucesso!")
# print(f"Encontrados {len(resultado.links_encontrados)} links")
# print(f"Nível de dificuldade: {resultado.nivel_dificuldade_navegacao}")


with open("teste.html", "w") as f:
    f.write(html_content)


# print(user_prompt)





import litellm

response = await litellm.acompletion(
    model="deepseek/deepseek-chat",
    response_format={"type": "json_object"},
    messages=[
        {
            "role": "system",
            "content": system_prompt,
        },
        {"role": "user", "content": user_prompt},
    ],
)

cost = litellm.completion_cost(completion_response=response)
print(response.choices[0].message.content)
print(f"Custo da requisição: R$ {5.5 * cost:.4f}")





cost


import tokencost

costs = tokencost.calculate_all_costs_and_tokens(
    prompt=system_prompt + user_prompt,
    completion=response.choices[0].message.content,
    model="gpt-4o-mini",
    a,
)

costs




















# show_base64(screenshot_base64)


from pydantic import BaseModel

city = "Poços de Caldas"
uf = "MG"

history = [
    {
        "type": "contexto",
        "message": (f"O usuário jé se apresentou a você lhe informou o seu objetivo"),
    },
    {
        "type": "contexto",
        "message": "O usuário ja lhe forneceu a url da página principal",
    },
    {
        "type": "seu pensamento",
        "message": '"Preciso definir se tem algum link interessante nessa página que me leve a uma outra página onde terei a tabela com a relação nominal de salário. "',
    },
]


formatted_history = "\n".join(
    [f"Step {i+1}: [{x['type']}] {x['message']}" for i, x in enumerate(history)]
)

prompt = f"""
<objetivo>
Encontrar uma forma de obter o salário nominal de cada uma dos servidores públicos da cidade de {city} - {uf}
</objetivo>

<sua-tarefa>
Verfique no html da página se existem links relevantes que leval a outras páginas onde possivelmente
poderei encontrar a relação entre nome e salário dos servidores públicos da cidade de {city} - {uf}.
</sua-tarefa>

<html-da-pagina>
{html}
</html-da-pagina>

<history>
{formatted_history}
</history>
"""


class LLMCompletion(BaseModel):
    relevant_links: list[str]


# print(prompt)


costs = tokencost.calculate_all_costs_and_tokens(
    prompt=formatted_history, completion="", model="gpt-4o-mini"
)

costs





import litellm

response = await litellm.acompletion(
    model="gpt-4o-mini",
    response_format=LLMCompletion,
    messages=[
        {
            "role": "system",
            "content": "Você é um assistente especialista em navegação web.",
        },
        {"role": "user", "content": prompt},
    ],
)

cost = litellm.completion_cost(completion_response=response)
print(response.choices[0].message.content)
print(f"Custo da requisição: R$ {5.5 * cost:.2f}")


url = "https://descomplica.pocosdecaldas.mg.gov.br"

proxy_config = get_proxy()

assert await test_proxy(proxy_config)

async with async_playwright() as playwright:
    browser = await set_browser(playwright, engine="random", proxy=proxy_config)
    context = await set_context(browser)
    page = await set_page(context)
    await page.goto(url, wait_until="networkidle")
    html = await page.content()

response = await litellm.acompletion(
    model="gpt-4o-mini",
    response_format=LLMCompletion,
    messages=[
        {
            "role": "system",
            "content": "Você é um assistente especialista em navegação web.",
        },
        {"role": "user", "content": prompt},
    ],
)

cost = litellm.completion_cost(completion_response=response)
print(response.choices[0].message.content)
print(f"Custo da requisição: R$ {5.5 * cost:.2f}")



































# print(html)


proxy_config = get_proxy()
print_proxy_safe(proxy_config)








import os


from openai import OpenAI

client = OpenAI(
    api_key=os.environ["DEEPSEEK_API_KEY"], base_url="https://api.deepseek.com"
)

response = client.chat.completions.create(
    model="deepseek-chat",
    messages=[
        {"role": "system", "content": "You are a helpful assistant"},
        {"role": "user", "content": "Hello"},
    ],
    stream=False,
)

print(response.choices[0].message.content)

















get_ipython().getoutput("pip install browser-use -qqq")


import asyncio
import os

from browser_use import Agent
from browser_use.llm import ChatOpenAI

llm = ChatOpenAI(
    base_url="https://api.deepseek.com/v1",  # ou sua instância local
    api_key=os.environ["DEEPSEEK_API_KEY"],
    model="deepseek-v3",
)

# llm = ChatOpenAI(
#     api_key=os.environ["OPENAI_API_KEY"],
#     model="gpt-4o-mini",
# )

agent = Agent(
    task="encontre o link para a pagia onde eu consiga encontrar o salário dos servidores públicos municipais da cidade de resende-rj",
    llm=llm,
)
await agent.run()











import asyncio
import json

from browser_use import Agent
from browser_use.llm import ChatOpenAI

llm = ChatOpenAI(
    base_url="https://api.deepseek.com/v1",  # ou sua instância local
    api_key=chave_deepseek,
    model="deepseek-v3",
)

agent = Agent(
    task="""
    Acesse o Google, busque por "melhores frameworks Python para IA em 2025".
    Extraia os 5 primeiros resultados com:
    - Título da página
    - Link da página
    - Um pequeno resumo (1-2 frases)

    Formate o resultado assim:
    [
      {
        "title": "Título da página",
        "url": "https://...",
        "summary": "Resumo do conteúdo"
      },
      ...
    ]
    Só responda com o JSON. Não inclua nenhuma explicação.
    """,
    llm=llm,
)

result = await agent.run()
print("RESULTADO:\n")
try:
    parsed = json.loads(result)
    for i, item in enumerate(parsed, 1):
        print(f"{i}. {item['title']}")
        print(f"   URL: {item['url']}")
        print(f"   RESUMO: {item['summary']}\n")
except Exception as e:
    print("Não foi possível converter para JSON:\n")
    print(result)





import asyncio
import json

from browser_use import Agent
from browser_use.llm import ChatOpenAI


async def main():
    agent = Agent(
        task="""
        Acesse o Google, busque por "melhores frameworks Python para IA em 2025".
        Extraia os 5 primeiros resultados com:
        - Título da página
        - Link da página
        - Um pequeno resumo (1-2 frases)

        Formate o resultado assim:
        [
          {
            "title": "Título da página",
            "url": "https://...",
            "summary": "Resumo do conteúdo"
          },
          ...
        ]
        Só responda com o JSON. Não inclua nenhuma explicação.
        """,
        llm=ChatOpenAI(model="gpt-4o", temperature=0.3),
    )

    result = await agent.run()
    print("RESULTADO:\n")
    try:
        parsed = json.loads(result)
        for i, item in enumerate(parsed, 1):
            print(f"{i}. {item['title']}")
            print(f"   URL: {item['url']}")
            print(f"   RESUMO: {item['summary']}\n")
    except Exception as e:
        print("Não foi possível converter para JSON:\n")
        print(result)


asyncio.run(main())





page


url = "https://www.bing.com/search?q=portal+de+transparencia+resende"

async with async_playwright() as playwright:
    browser = await set_browser(playwright, engine="random")
    context = await set_context(browser)
    page = await set_page(context)

    try:
        print("Navegar para o Google")
        await page.goto(url, wait_until="networkidle")

        print("Pegar conteúdo da página")
        html_page = await page.content()

        # print("Aguardar o campo de busca aparecer e clicar nele")
        # search_input = page.locator('input[name="q"]')
        # await search_input.wait_for(state="visible")

        # print("Digitar a consulta")
        # await search_input.fill(query)

        # print("Pressionar Enter ou clicar no botão de busca")
        # await search_input.press("Enter")

        # print("Aguardar os resultados carregarem")
        # await page.wait_for_selector('#search', timeout=10000)

        # print("Aguardar um pouco mais para garantir que todos os resultados carregaram")
        # await page.wait_for_timeout(2000)

        # print("Coletar os resultados de busca")

    except Exception as e:
        print(f"Erro durante a busca: {e}")

    finally:
        await browser.close()


html_page

















# TÉCNICAS AVANÇADAS PARA EVITAR DETECÇÃO

# 1. HUMANIZAÇÃO EXTREMA
import asyncio
import math
import random


async def human_mouse_movement(page, start_x, start_y, end_x, end_y):
    """Simula movimento de mouse humano com curvas naturais"""

    steps = random.randint(15, 25)

    for i in range(steps):
        progress = i / steps

        # Curva Bézier para movimento natural
        control_x = start_x + random.uniform(-50, 50)
        control_y = start_y + random.uniform(-50, 50)

        # Calcular posição atual
        current_x = (
            (1 - progress) ** 2 * start_x
            + 2 * (1 - progress) * progress * control_x
            + progress**2 * end_x
        )
        current_y = (
            (1 - progress) ** 2 * start_y
            + 2 * (1 - progress) * progress * control_y
            + progress**2 * end_y
        )

        # Adicionar pequenas variações
        current_x += random.uniform(-2, 2)
        current_y += random.uniform(-2, 2)

        await page.mouse.move(current_x, current_y)
        await asyncio.sleep(random.uniform(0.01, 0.03))


async def human_typing(page, element, text):
    """Digitação com padrões humanos realistas"""

    await element.click()
    await asyncio.sleep(random.uniform(0.1, 0.3))

    for i, char in enumerate(text):
        # Velocidade variável (mais lento no início, mais rápido depois)
        base_delay = 0.12 if i < 3 else 0.08

        # Caracteres especiais demoram mais
        if char in " -_@.":
            delay = base_delay * random.uniform(1.5, 2.5)
        else:
            delay = base_delay * random.uniform(0.7, 1.3)

        # Pequena chance de pausar (pensando)
        if random.random() < 0.05:
            delay += random.uniform(0.5, 1.5)

        await element.type(char)
        await asyncio.sleep(delay)


# 2. BROWSER FINGERPRINTING AVANÇADO
async def setup_realistic_browser(playwright):
    """Configura browser com fingerprint extremamente realista"""

    # Fingerprints reais coletados de browsers verdadeiros
    realistic_configs = [
        {
            "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "viewport": {"width": 1920, "height": 1080},
            "screen": {"width": 1920, "height": 1080},
            "timezone": "America/Sao_Paulo",
            "locale": "pt-BR",
            "platform": "Win32",
        },
        {
            "user_agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "viewport": {"width": 1440, "height": 900},
            "screen": {"width": 1440, "height": 900},
            "timezone": "America/Sao_Paulo",
            "locale": "pt-BR",
            "platform": "MacIntel",
        },
    ]

    config = random.choice(realistic_configs)

    browser = await playwright.chromium.launch(
        headless=True,
        args=[
            "--no-sandbox",
            "--disable-setuid-sandbox",
            "--disable-dev-shm-usage",
            "--disable-blink-features=AutomationControlled",
            "--exclude-switches=enable-automation",
            "--disable-extensions",
            "--disable-plugins-discovery",
            "--disable-plugins",
            "--disable-preconnect",
            "--disable-gpu",
            "--no-first-run",
            "--no-service-autorun",
            "--password-store=basic",
            "--system-developer-mode",
            "--mute-audio",
            "--no-zygote",
            "--no-default-browser-check",
            "--disable-backgrounding-occluded-windows",
            "--disable-renderer-backgrounding",
            "--disable-features=TranslateUI",
            "--disable-ipc-flooding-protection",
            f'--window-size={config["viewport"]["width"]},{config["viewport"]["height"]}',
        ],
    )

    context = await browser.new_context(
        user_agent=config["user_agent"],
        viewport=config["viewport"],
        screen=config["screen"],
        locale=config["locale"],
        timezone_id=config["timezone"],
        permissions=["geolocation"],
        geolocation={"latitude": -22.4609, "longitude": -44.4444},  # Resende, RJ
        extra_http_headers={
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Accept-Language": "pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7",
            "Cache-Control": "max-age=0",
            "Sec-Ch-Ua": '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            "Sec-Ch-Ua-Mobile": "?0",
            "Sec-Ch-Ua-Platform": f'"{config["platform"]}"',
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Sec-Fetch-User": "?1",
            "Upgrade-Insecure-Requests": "1",
        },
    )

    return browser, context


# 3. STEALTH SCRIPTS AVANÇADOS
ADVANCED_STEALTH_SCRIPT = """
(() => {
    // 1. Remover propriedades de automação
    delete navigator.__proto__.webdriver;
    delete navigator.webdriver;
    
    // 2. Mockear propriedades ausentes
    Object.defineProperty(navigator, 'webdriver', {
        get: () => undefined,
        configurable: true
    });
    
    // 3. Simular plugins reais
    Object.defineProperty(navigator, 'plugins', {
        get: () => [
            {
                0: {type: "application/x-google-chrome-pdf", suffixes: "pdf", description: "Portable Document Format", enabledPlugin: Plugin},
                description: "Portable Document Format",
                filename: "internal-pdf-viewer",
                length: 1,
                name: "Chrome PDF Plugin"
            },
            {
                0: {type: "application/pdf", suffixes: "pdf", description: "Portable Document Format", enabledPlugin: Plugin},
                description: "Portable Document Format", 
                filename: "mhjfbmdgcfjbbpaeojofohoefgiehjai",
                length: 1,
                name: "Chrome PDF Viewer"
            }
        ]
    });
    
    // 4. Simular propriedades de hardware
    Object.defineProperty(navigator, 'hardwareConcurrency', {
        get: () => 8
    });
    
    Object.defineProperty(navigator, 'deviceMemory', {
        get: () => 8
    });
    
    // 5. Mockear WebGL fingerprint
    const getParameter = WebGLRenderingContext.getParameter;
    WebGLRenderingContext.prototype.getParameter = function(parameter) {
        if (parameter === 37445) {
            return 'NVIDIA Corporation';
        }
        if (parameter === 37446) {
            return 'NVIDIA GeForce GTX 1060 6GB/PCIe/SSE2';
        }
        return getParameter(parameter);
    };
    
    // 6. Mockear screen properties
    Object.defineProperty(screen, 'availWidth', {
        get: () => window.screen.width
    });
    
    Object.defineProperty(screen, 'availHeight', {
        get: () => window.screen.height - 40  // Taskbar
    });
    
    // 7. Adicionar propriedades do Chrome ausentes
    if (!window.chrome) {
        window.chrome = {
            app: {
                isInstalled: false,
                InstallState: {
                    DISABLED: 'disabled',
                    INSTALLED: 'installed',
                    NOT_INSTALLED: 'not_installed'
                },
                RunningState: {
                    CANNOT_RUN: 'cannot_run',
                    READY_TO_RUN: 'ready_to_run',
                    RUNNING: 'running'
                }
            },
            runtime: {
                OnInstalledReason: {
                    CHROME_UPDATE: 'chrome_update',
                    INSTALL: 'install',
                    SHARED_MODULE_UPDATE: 'shared_module_update',
                    UPDATE: 'update'
                },
                OnRestartRequiredReason: {
                    APP_UPDATE: 'app_update',
                    OS_UPDATE: 'os_update',
                    PERIODIC: 'periodic'
                },
                PlatformArch: {
                    ARM: 'arm',
                    ARM64: 'arm64',
                    MIPS: 'mips',
                    MIPS64: 'mips64',
                    X86_32: 'x86-32',
                    X86_64: 'x86-64'
                },
                PlatformNaclArch: {
                    ARM: 'arm',
                    MIPS: 'mips',
                    MIPS64: 'mips64',
                    X86_32: 'x86-32',
                    X86_64: 'x86-64'
                },
                PlatformOs: {
                    ANDROID: 'android',
                    CROS: 'cros',
                    FREEBSD: 'freebsd',
                    LINUX: 'linux',
                    MAC: 'mac',
                    OPENBSD: 'openbsd',
                    WIN: 'win'
                },
                RequestUpdateCheckStatus: {
                    NO_UPDATE: 'no_update',
                    THROTTLED: 'throttled',
                    UPDATE_AVAILABLE: 'update_available'
                }
            }
        };
    }
    
    // 8. Remover automation flags
    Object.defineProperty(navigator, 'languages', {
        get: () => ['pt-BR', 'pt', 'en-US', 'en']
    });
    
    // 9. Simular permissions reais
    const originalQuery = window.navigator.permissions.query;
    window.navigator.permissions.query = (parameters) => (
        parameters.name === 'notifications' ?
            Promise.resolve({ state: Notification.permission }) :
            originalQuery(parameters)
    );
    
    // 10. Adicionar event listeners naturais
    ['mousedown', 'mouseup', 'click', 'mousemove'].forEach(eventType => {
        document.addEventListener(eventType, () => {}, true);
    });
    
})();
"""


# 4. FUNÇÃO PRINCIPAL COM TODAS AS TÉCNICAS
async def ultimate_stealth_search(query):
    """Busca com técnicas stealth de última geração"""

    async with async_playwright() as playwright:
        browser, context = await setup_realistic_browser(playwright)
        page = await context.new_page()

        # Aplicar script stealth
        await page.add_init_script(ADVANCED_STEALTH_SCRIPT)

        try:
            print("🕵️ Iniciando busca stealth de última geração...")

            # Navegar com comportamento humano
            await page.goto("https://www.google.com.br")
            await asyncio.sleep(random.uniform(2, 4))

            # Simular comportamento de usuário real
            await page.mouse.move(100, 100)
            await asyncio.sleep(0.5)

            # Scroll para baixo e para cima (comportamento natural)
            await page.mouse.wheel(0, 200)
            await asyncio.sleep(0.5)
            await page.mouse.wheel(0, -100)
            await asyncio.sleep(1)

            # Encontrar campo de busca
            search_box = page.locator('input[name="q"]').first
            await search_box.wait_for(state="visible")

            # Movimento natural do mouse até o campo
            box = await search_box.bounding_box()
            if box:
                await human_mouse_movement(
                    page,
                    random.randint(100, 300),
                    random.randint(100, 300),
                    box["x"] + box["width"] / 2,
                    box["y"] + box["height"] / 2,
                )

            # Digitação humana
            await human_typing(page, search_box, query)

            # Pausa antes de pressionar Enter
            await asyncio.sleep(random.uniform(0.5, 1.5))
            await search_box.press("Enter")

            # Aguardar com comportamento natural
            await asyncio.sleep(random.uniform(3, 6))

            # Verificar se chegaram resultados
            try:
                await page.wait_for_selector(".g, #search", timeout=10000)
                print("✅ Resultados carregados com sucesso!")

                # Coletar resultados (mesmo código anterior)
                results = []
                search_results = await page.query_selector_all(".g")

                for i, result in enumerate(search_results[:10]):
                    try:
                        title_el = await result.query_selector("h3")
                        title = (
                            await title_el.inner_text() if title_el else "Sem título"
                        )

                        url_el = await result.query_selector("a")
                        url = (
                            await url_el.get_attribute("href") if url_el else "Sem URL"
                        )

                        snippet_el = await result.query_selector(".VwiC3b, .s3v9rd")
                        snippet = (
                            await snippet_el.inner_text()
                            if snippet_el
                            else "Sem snippet"
                        )

                        if title != "Sem título" and url != "Sem URL":
                            results.append(
                                {
                                    "position": i + 1,
                                    "title": title.strip(),
                                    "url": url,
                                    "snippet": snippet.strip(),
                                }
                            )

                    except Exception:
                        continue

                return results

            except:
                # Verificar se foi bloqueado
                captcha = await page.query_selector("#recaptcha, .g-recaptcha")
                if captcha:
                    print("❌ Ainda detectado como bot")
                else:
                    print("❌ Timeout nos resultados")
                return None

        finally:
            await browser.close()


# 5. EXEMPLO DE USO
async def main():
    query = "portal de transparência de Resende - RJ"
    results = await ultimate_stealth_search(query)

    if results:
        print(f"\n🎉 SUCESSO! {len(results)} resultados obtidos")
        for r in results[:3]:
            print(f"• {r['title']}")
    else:
        print("❌ Ainda não foi possível burlar a detecção")


if __name__ == "__main__":
    asyncio.run(main())









